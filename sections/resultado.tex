\chapter{Resultados Preliminares e Considerações}
\section{Desempenho Computacional}
Na Figura \ref{fig:clustera} são apresentados os valores de \textit{speed up} das
simulações com diferentes números de processadores. Como se pode perceber, foi 
possível alcançar uma diminuição no tempo de execução com as simulações feitas em
paralelo, de forma que os valores de \textit{speed up} aumentam de forma linear,
aproximadamente. Na Figura \ref{fig:clusterb}, por sua vez, são apresentados os valores das
eficiências calculadas. Esses valores são
bem próximos para 2, 4 e 8 processos, mas uma queda começa a se tornar visível em
16 processos, sugerindo que, a partir desse número, a queda de eficiência se 
acentue.

\begin{figure}[ht]
    \centering
    \subfloat[][]{
        \label{fig:clustera}
        \includegraphics[scale=0.3]{linear}
    }
    ~ 
    \subfloat[][]{
        \label{fig:clusterb}
        \includegraphics[scale=0.3]{efs}
    }
    \caption[Resultados de aceleração e eficiência em função do número de processadores]{
        \subref{fig:clustera} Os círculos representam o \textit{speed up} obtido para cada
        número de processador utilizado. A reta em azul mostra uma regressão linear dos
        resultados. \subref{fig:clusterb} eficiência em função do número de processadores.
         }
\end{figure}

Outro resultado sobre desempenho computacional obtido foi o de tempo de
execução com as matrizes de condutância alteradas no Python. Como mostrado na 
Tabela \ref{tab:matrixG}, não é observada uma melhora de desempenho quando se 
usa a $G_g$ para 10 MNs. Entretanto, a medida em que se aumentam
o número de elementos neuronais para 50, 100 e 400 MNs, esta implementação
apresenta uma diminuição do tempo de execução de aproximadamente 23\%, 29\% e
26\% em relação à $G_c$ com
10, 50, 100 e 400 MNs, respectivamente. Isso sugere que as otimizações trazidas
por essa estratégia só são vantajosas para simulações que envolvam $G_g$
relativamente grandes. Como essas matrizes são esparsas, algoritmos que se
aproveitam dessa estrutura podem ser usados para reduzir ainda mais o tempo de
simulação.

\begin{table}[ht]
\caption{Tempo de execução das simulações relacionadas 
         à matriz de condutância para diferentes quantidades de MNs.}
\label{tab:matrixG}
\centering
    \begin{tabular}{ccccc}\hline 
        & 10 MNs & 50 MNs & 100 MNs & 400 MNs \\ \hline 
        $G_c$ & 5.21 s & 21.22 s & 42.34 s & 170.97 s \\ 
        $G_g$ & 5.63 s & 16.50 s & 30.01 s & 125.31 s \\ 
	\hline
    \end{tabular}
\end{table}

Os resultados mostrados anteriormente são positivos, mas possuem muitas
limitações. Em primeiro lugar, apesar das melhoras obtidas com a matriz
$G_g$, a diferença de tempo de execução entre as versões Java e Python
ainda são muito grandes e outras soluções precisariam ser exploradas
para diminuir essa discrepância.

Em segundo lugar, é preciso enfatizar que os MNs das simulações
realizadas no \textit{cluster} não recebem nenhuma entrada sináptica
de INs. A paralelização desse tipo de configuração é
facilmente obtida e dificilmente apresenta resultados negativos, pois,
como as unidades motoras são independentes umas das outras, os
processos podem executar em paralelo sem a necessidade de se comunicar. 
Em um cenário mais realista, como o que está sendo estudado na Figura
\ref{fig:circuit}, MNs em um processo podem precisar receber informações
geradas em outro. Por causa da alta complexidade de conexões
sinapticas, seriam necessárias muitas comunicações entre processos
e isso poderia causar uma diminuição significativa nos valores de
\textit{speed up}.

Isso, de qualquer forma, não tira a validade desse resultado, visto
que existem maneiras de paralelizar simuladores de redes neuronais
complexas mantendo um bom desempenho computacional \cite{morrison05}.
Entretanto, pode-se perceber que os resultados obtidos no \textit{cluster},
em essência, poderiam ser reproduzidos em computadores comuns por meio
da utilização de \textit{threads} ou processos. O uso destas estratégias,
na verdade, seria preferível à utilização de um \textit{cluster}, pois
envolvem menos alterações na estrutura do código do simulador e
possibilitam que outras pessoas interessadas em utilizar esse
\textit{software} possam fazer simulações com um bom desempenho
computacional em seus próprios computadores.

A utilização de \textit{threads} no Python, entretanto, não é
possível por causa do \textit{Global Interpreter Lock} (GIL). Esse
mecanismo faz com que apenas uma \textit{thread} exista por processo.
Uma alternativa para essa limitação é o uso de processos para realizar
a paralelização do código. Esse recurso pode ser explorado no Python
através da biblioteca \textit{Multiprocessing} e pode trazer melhoras
significativas, especialmente quando há a possibilidade de se trabalhar
com memória compartilhada. O código do simulador, no entanto, teria que
passar por grandes modificações e sua estrutura de orientação a objetos
não é muito compatível com essa biblioteca. Além disso, a elevado 
volume de comunicações entre processos aqui também seria um gargalo.

Sendo assim, de acordo com as observações feitas, convém propor outras
estratégias para alcançar um aumento no desempenho computacional. Para
esse fim, o Cython surge como uma boa alternativa e será explorado 
nesse trabalho, já que seu uso pode ocasionar em tempos de execução
muitas vezes similares ao de um código escrito em C \cite{gorelick14}.
Vale notar que o uso de \textit{clusters} ainda seria uma boa solução,
mas por causa da dificuldade de tal implementação e da existência de
outras opções, esta é postergada para trabalhos futuros.

%\begin{table}[ht!]
%\caption{Tempo de execução das simulações relacionadas 
%         à matriz de condutância para diferentes tempos simulados.}
%\label{tab:matrixGt}
%\centering
%    \begin{tabular}{cccc}\hline 
%        & 200 ms & 500 ms & 1000 ms \\ \hline 
%        $G_c$ & 21.52 s & 53.03129 s &  s \\ 
%        $G_g$ & 16.55 s & 41.15 s &  s \\ 
%	\hline
%    \end{tabular}
%\end{table}

\section{Disparos dos Elementos Neuronais}
Na Figura \ref{fig:spkOldxNew}, cada MN é representado por índices, que 
são distribuídos em ordem crescente no eixo vertical da figura e atribuídos de
forma que seus valores sejam diretamente proporcionais ao tamanho dos
neurônios aos quais estão associados. O eixo horizontal representa os instantes
de disparo, que podem ser observados para cada índice. 

Pode-se perceber que o uso das
parametrizações nova e antiga resulta em padrões de disparos claramente
distintos. Na nova, os MNs disparam de forma ordenada, do menor para o maior 
(com algumas pequenas variações).
Por outro lado, na antiga, a alta inibição das CRs nos MNs faz com que
alguns destes, em certos instantes, atrasem seus disparos. Como resultado, o
gráfico dos instantes de disparos, nesse caso, possui um aspecto ``fragmentado''.

\begin{figure}[ht]
	\center
	\includegraphics[scale=0.4]{spkOldxNew.png}
    \caption[Momentos de disparo dos somas de todos os motoneurônios simulados.]{
             Momentos de disparo dos somas de todos os motoneurônios simulados.
             O eixo das ordenadas representa os MNs e o eixo das abcissas, os
             instantes de disparo. Os disparos dos MNs, com
             parametrização nova e antiga das CRs, estão sobrepostos.
            }
	\label{fig:spkOldxNew}
\end{figure}

Essa característica dos instantes de disparos usando a parametrização antiga
pode ser melhor observado na Figura 
\ref{fig:spkTimes}. É possível perceber na Figura
\ref{fig:spkTimes}\subref{fig:spkOldZoom1} que algumas unidades com índice 
próximo a 25 dispararam em 340 ms. Por volta de 25 ms antes, unidades com
índice perto de 60 já tinham disparado. Na Figura
\ref{fig:spkTimes}\subref{fig:spkOldZoom2}, pode-se perceber que uma unidade
do tipo FR, de índice 801, dispara mais de 60 ms antes do que a do índice
anterior, que é do tipo S. Dessa forma, esses gráficos indicam que ocorreu
uma certa inversão na ordem de recrutamento.

\begin{figure}[ht]
    \centering
    \subfloat[][]{
        \label{fig:spkOldZoom1}
        \includegraphics[scale=0.275]{spkOldZoom1.png}
    }
    ~ 
    \subfloat[][]{
        \label{fig:spkOldZoom2}
        \includegraphics[scale=0.25]{spkOldZoom2.png}
    }
    \caption[Visão de um intervalo reduzido dos disparos dos motoneurônios na
             parametrização antiga.]{
             Visão de um intervalo reduzido dos disparos dos motoneurônios na 
             parametrização antiga.
             \subref{fig:spkOldZoom1} Instantes de disparos dos primeiros
             motoneurônios nos instantes iniciais. \subref{fig:spkOldZoom2}
             Instantes de disparos dos últimos motoneurônios nos instantes
             finais.
         }
    \label{fig:spkTimes}
\end{figure}

Para verificar se a força inibitória das CRs poderiam estar causando esse
comportamento, apenas os valores das condutâncias entre CRs e MNs da
parametrização antiga foram substituídos por aqueles descrito em
\citeonline{maltenfort98}. O resultado dessa simulação é mostrado 
na Figura \ref{fig:spkMaltenfort}\subref{fig:spkOldMaltenfort}. A aparência
fragmentada dos disparos de MNs aparentemente desapareceu, mas
uma visão de um intervalo de tempo reduzido, como o da Figura
\ref{fig:spkMaltenfort}\subref{fig:spkOldMaltenfortZoom}, mostra que
o padrão se tornou menos evidente. Esse resultado, no entanto, deixa em aberto
como que as CRs estão influenciado os MNs, sendo necessário realizar
novamente algumas validações do circuito de inibição recorrente.

\begin{figure}[ht]
    \centering
    \subfloat[][]{
        \label{fig:spkOldMaltenfort}
        \includegraphics[scale=0.25]{spkOldMaltenfort.png}
    }
    ~ 
    \subfloat[][]{
        \label{fig:spkOldMaltenfortZoom}
        \includegraphics[scale=0.275]{spkOldMaltenfortZoom.png}
    }
    \caption[Momentos de disparo dos somas de todos os motoneurônios
             simulados com as condutâncias reportadas por
             \citeonline{maltenfort98}.]{Momentos de disparo dos somas
             de todos os motoneurônios simulados com as condutâncias
             reportadas por
             \citeonline{maltenfort98}. \subref{fig:spkOldMaltenfort} Visão 
             geral. \subref{fig:spkOldMaltenfortZoom} 
             Visão dos disparos em um intervalo reduzido.
         }
    \label{fig:spkMaltenfort}

\section{Parametrizações}
As parametrizações foram realizadas na ordem em que são apresentadas.
A dependência de uma parametrização com outra, quando existente, é reportada
em cada caso.

\subsection{Potencial Excitatório Pós Sinápico nas Células de Renshaw}
A resistência específica da CR foi ajustada para reproduzir os 
seguintes resultados descritos na literatura:

\begin{itemize}
    \item \citeonline{walmsley81}: Medições da atividade intracelular em
        CRs após uma estimulação de raízes ventrais forneceram alguns
        dados sobre os PEPSs resultantes.
    \item \citeonline{williams09}: Nesse trabalho de simulações, os
        autores adotam 7.6 ms de tempo de subida e 50 ms de duração 
        dos PEPSs descritos por \citeonline{walmsley81}.
    \item \citeonline{fyffe91}: Conexões sinápticas de CRs para MNs do 
        tipo $\alpha$ são localizadas nos dendritos.
\end{itemize}

Para simular o experimento descrito, corrente foi injetada no soma de um
MN que fazia sinapse com uma CR.

Um estímulo aplicado nas raízes ventrais irá ativar primeiramente as 
unidades motoras maiores. Por essa razão, apenas um MNs do tipo FF foram 
simulados. Além disso, como esse tipo de estimulação pode facilmente 
recrutar mais de um motoneurônio, a parametrização não levou em conta a
amplitude do PEPS

\subsubsection{Limitações}
\subsection{Pós Hiperpolarização das Células de Renshaw}
\subsubsection{Limitações}
\end{figure}
