\chapter{Resultados Preliminares e Considerações}
\section{Desempenho Computacional}
Na Figura \ref{fig:clustera} são apresentados os valores de \textit{speed up} das
simulações com diferentes números de processadores. Como se pode perceber, foi 
possível alcançar uma diminuição no tempo de execução com as simulações feitas em
paralelo, de forma que os valores de \textit{speed up} aumentam de forma linear,
aproximadamente. Na Figura \ref{fig:clusterb}, por sua vez, são apresentados os valores das
eficiências calculadas. Esses valores são
bem próximos para 2, 4 e 8 processos, mas uma queda começa a se tornar visível em
16 processos, sugerindo que, a partir desse número, a queda de eficiência se 
acentue.

\begin{figure}[ht]
    \centering
    \subfloat[][]{
        \label{fig:clustera}
        \includegraphics[scale=0.3]{linear}
    }
    ~ 
    \subfloat[][]{
        \label{fig:clusterb}
        \includegraphics[scale=0.3]{efs}
    }
    \caption[Resultados de aceleração e eficiência em função do número de processadores]{
        \subref{fig:clustera} Os círculos representam o \textit{speed up} obtido para cada
        número de processador utilizado. A reta em azul mostra uma regressão linear dos
        resultados. \subref{fig:clusterb} eficiência em função do número de processadores.
         }
\end{figure}

Outro resultado sobre desempenho computacional obtido foi o de tempo de
execução com as matrizes de condutância alteradas no Python. Como mostrado na 
Tabela \ref{tab:matrixG}, não é observada uma melhora de desempenho quando se 
usa a $G_g$ para 10 MNs. Entretanto, a medida em que se aumentam
o número de elementos neuronais para 50, 100 e 400 MNs, esta implementação
apresenta uma diminuição do tempo de execução de aproximadamente 23\%, 29\% e
26\% em relação à $G_c$ com
10, 50, 100 e 400 MNs, respectivamente. Isso sugere que as otimizações trazidas
por essa estratégia só são vantajosas para simulações que envolvam $G_g$
relativamente grandes. Como essas matrizes são esparsas, algoritmos que se
aproveitam dessa estrutura podem ser usados para reduzir ainda mais o tempo de
simulação.

\begin{table}[ht]
\caption{Tempo de execução das simulações relacionadas 
         à matriz de condutância para diferentes quantidades de MNs.}
\label{tab:matrixG}
\centering
    \begin{tabular}{ccccc}\hline 
        & 10 MNs & 50 MNs & 100 MNs & 400 MNs \\ \hline 
        $G_c$ & 5.21 s & 21.22 s & 42.34 s & 170.97 s \\ 
        $G_g$ & 5.63 s & 16.50 s & 30.01 s & 125.31 s \\ 
	\hline
    \end{tabular}
\end{table}

Os resultados mostrados anteriormente são positivos, mas possuem muitas
limitações. Em primeiro lugar, apesar das melhoras obtidas com a matriz
$G_g$, a diferença de tempo de execução entre as versões Java e Python
ainda são muito grandes e outras soluções precisariam ser exploradas
para diminuir essa discrepância.

Em segundo lugar, é preciso enfatizar que os MNs das simulações
realizadas no \textit{cluster} não recebem nenhuma entrada sináptica
de INs. A paralelização desse tipo de configuração é
facilmente obtida e dificilmente apresenta resultados negativos, pois,
como as unidades motoras são independentes umas das outras, os
processos podem executar em paralelo sem a necessidade de se comunicar. 
Em um cenário mais realista, como o que está sendo estudado na Figura
\ref{fig:circuit}, MNs em um processo podem precisar receber informações
geradas em outro. Por causa da alta complexidade de conexões
sinapticas, seriam necessárias muitas comunicações entre processos
e isso poderia causar uma diminuição significativa nos valores de
\textit{speed up}.

Isso, de qualquer forma, não tira a validade desse resultado, visto
que existem maneiras de paralelizar simuladores de redes neuronais
complexas mantendo um bom desempenho computacional \cite{morrison05}.
Entretanto, pode-se perceber que os resultados obtidos no \textit{cluster},
em essência, poderiam ser reproduzidos em computadores comuns por meio
da utilização de \textit{threads} ou processos. O uso destas estratégias,
na verdade, seria preferível à utilização de um \textit{cluster}, pois
envolvem menos alterações na estrutura do código do simulador e
possibilitam que outras pessoas interessadas em utilizar esse
\textit{software} possam fazer simulações com um bom desempenho
computacional em seus próprios computadores.

A utilização de \textit{threads} no Python, entretanto, não é
possível por causa do \textit{Global Interpreter Lock} (GIL). Esse
mecanismo faz com que apenas uma \textit{thread} exista por processo.
Uma alternativa para essa limitação é o uso de processos para realizar
a paralelização do código. Esse recurso pode ser explorado no Python
através da biblioteca \textit{Multiprocessing} e pode trazer melhoras
significativas, especialmente quando há a possibilidade de se trabalhar
com memória compartilhada. O código do simulador, no entanto, teria que
passar por grandes modificações e sua estrutura de orientação a objetos
não é muito compatível com essa biblioteca. Além disso, a elevado 
volume de comunicações entre processos aqui também seria um gargalo.

Sendo assim, de acordo com as observações feitas, convém propor outras
estratégias para alcançar um aumento no desempenho computacional. Para
esse fim, o Cython surge como uma boa alternativa e será explorado 
nesse trabalho, já que seu uso pode ocasionar em tempos de execução
muitas vezes similares ao de um código escrito em C \cite{gorelick14}.
Vale notar que o uso de \textit{clusters} ainda seria uma boa solução,
mas por causa da dificuldade de tal implementação e da existência de
outras opções, esta é postergada para trabalhos futuros.

%\begin{table}[ht!]
%\caption{Tempo de execução das simulações relacionadas 
%         à matriz de condutância para diferentes tempos simulados.}
%\label{tab:matrixGt}
%\centering
%    \begin{tabular}{cccc}\hline 
%        & 200 ms & 500 ms & 1000 ms \\ \hline 
%        $G_c$ & 21.52 s & 53.03129 s &  s \\ 
%        $G_g$ & 16.55 s & 41.15 s &  s \\ 
%	\hline
%    \end{tabular}
%\end{table}

\section{Disparos dos Elementos Neuronais}
Na Figura \ref{fig:spkTimes}, cada MN é representado por índices, que 
são distribuídos em ordem crescente no eixo vertical da figura e atribuídos de
forma que seus valores sejam diretamente proporcionais ao tamanho dos
neurônios aos quais estão associados. O eixo horizontal representa os instantes
de disparo, que podem ser observados para cada índice. 

Como visto na Figura \ref{fig:spkTimes}\subref{fig:spkOldxNew}, o uso das
parametrizações nova e antiga resulta em padrões de disparos claramente
distintos. Na nova, os MNs disparam de forma ordenada, do menor para o maior 
(com algumas pequenas variações).
Por outro lado, na antiga, a alta inibição das CRs nos MNs faz com que
alguns destes, em certos instantes, atrasem seus disparos. Como resultado, o
gráfico dos instantes de disparos, nesse caso, possui um aspecto ``fragmentado''.

Essa característica dos instantes de disparos usando a parametrização antiga
pode ser melhor observado na Figura 
\ref{fig:spkTimes}\subref{fig:spkOldZoom}. É possível perceber que existem MNs
maiores disparando antes de outros menores, indicando,
assim, que ocorreu uma certa inversão na ordem de recrutamento.

\begin{figure}[ht]
    \centering
    \subfloat[][]{
        \label{fig:spkOldxNew}
        \includegraphics[scale=0.25]{spkOldxNew.png}
    }
    ~ 
    \subfloat[][]{
        \label{fig:spkOldZoom}
        \includegraphics[scale=0.275]{spkOldZoom.png}
    }
    \caption[Momentos de disparo dos somas de todos os motoneurônios simulados.]{
             Momentos de disparo dos somas de todos os motoneurônios simulados.
             O eixo das ordenadas representa os MNs e o eixo das abcissas, os
             instantes de disparo. \subref{fig:spkOldxNew} Disparos da
             parametrização nova sobreposta à antiga. \subref{fig:spkOldZoom} 
             Zoom em uma parte do gráfico com parametrização antiga.
         }
    \label{fig:spkTimes}
\end{figure}

Para verificar se a força inibitória das CRs poderiam estar causando esse
comportamento, apenas os valores das condutâncias entre CRs e MNs da
parametrização antiga foram substituídos por aqueles descrito em
\citeonline{maltenfort98}.  O resultado dessa simulação é mostrado 
na Figura \ref{fig:spkMaltenfort}. De fato, a aparência fragmentado dos
disparos de MNs desapareceu. Esse resultado, no entanto, deixa em aberto
como que as CRs estão influenciado os MNs, sendo necessário realizar
novamente algumas validações do circuito de inibição recorrente.

\begin{figure}[ht]
	\center
	\includegraphics[scale=0.4]{spkOldMaltenfort.png}
	\caption{Momentos de disparo dos somas de todos os motoneurônios
            simulados com as condutâncias reportadas por
            \citeonline{maltenfort98}.}
	\label{fig:spkMaltenfort}
\end{figure}
