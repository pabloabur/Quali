\chapter{Resultados Preliminares e Considerações}
\section{Desempenho Computacional}
Na Figura \ref{fig:clustera} são apresentados os valores de \textit{speed up} das
simulações com diferentes números de processadores. Como se pode perceber, foi 
possível alcançar uma diminuição no tempo de execução com as simulações feitas em
paralelo, de forma que os valores de \textit{speed up} aumentam de forma linear,
aproximadamente. Na Figura \ref{fig:clusterb}, por sua vez, são apresentados os valores das
eficiências calculadas. Esses valores são
bem próximos para 2, 4 e 8 processos, mas uma queda começa a se tornar visível em
16 processos, sugerindo que, a partir desse número, a queda de eficiência se 
acentue.

\begin{figure}[ht]
    \centering
    \subfloat[][]{
        \label{fig:clustera}
        \includegraphics[scale=0.3]{linear}
    }
    ~ 
    \subfloat[][]{
        \label{fig:clusterb}
        \includegraphics[scale=0.3]{efs}
    }
    \caption[Resultados de aceleração e eficiência em função do número de processadores]{
        \subref{fig:clustera} Os círculos representam o \textit{speed up} obtido para cada
        número de processador utilizado. A reta em azul mostra uma regressão linear dos
        resultados. \subref{fig:clusterb} eficiência em função do número de processadores.
         }
\end{figure}

Outro resultado sobre desempenho computacional obtido foi o de tempo de
execução com as matrizes de condutância alteradas no Python. Como mostrado na 
Tabela \ref{tab:matrixG}, não é observada uma melhora de desempenho quando se 
usa a $G_g$ para 10 MNs. Entretanto, a medida em que se aumentam
o número de elementos neuronais para 50, 100 e 400 MNs, esta implementação
apresenta uma diminuição do tempo de execução de aproximadamente 23\%, 29\% e
26\% em relação à $G_c$ com
10, 50, 100 e 400 MNs, respectivamente. Isso sugere que as otimizações trazidas
por essa estratégia só são vantajosas para simulações que envolvam $G_g$
relativamente grandes. Como essas matrizes são esparsas, algoritmos que se
aproveitam dessa estrutura podem ser usados para reduzir ainda mais o tempo de
simulação.

\begin{table}[ht]
\caption{Tempo de execução das simulações relacionadas 
         à matriz de condutância para diferentes quantidades de MNs.}
\label{tab:matrixG}
\centering
    \begin{tabular}{ccccc}\hline 
        & 10 MNs & 50 MNs & 100 MNs & 400 MNs \\ \hline 
        $G_c$ & 5.21 s & 21.22 s & 42.34 s & 170.97 s \\ 
        $G_g$ & 5.63 s & 16.50 s & 30.01 s & 125.31 s \\ 
	\hline
    \end{tabular}
\end{table}

Os resultados mostrados anteriormente são positivos, mas possuem muitas
limitações. Em primeiro lugar, apesar das melhoras obtidas com a matriz
$G_g$, a diferença de tempo de execução entre as versões Java e Python
ainda são muito grandes e outras soluções precisariam ser exploradas
para resolver essa questão.

Em segundo lugar, é preciso enfatizar que os MNs das simulações
realizadas no \textit{cluster} não recebem nenhuma entrada sináptica
de INs. A paralelização desse tipo de configuração é
facilmente obtida e dificilmente apresenta resultados negativos, pois,
como as unidades motoras são independentes umas das outras, os
processos podem executar em paralelo sem a necessidade de se comunicar. 
Em um cenário mais realista, como o que está sendo estudado na Figura
\ref{fig:circuit}, MNs em um processo podem precisar receber informações
geradas em outro. Por causa da alta complexidade de conexões
sinapticas, seriam necessárias muitas comunicações entre os processos
e isso poderia causar uma diminuição significativa nos valores de
\textit{speed up}.

Isso, de qualquer forma, não tira a validade desse resultado, visto
que existem maneiras de paralelizar simuladores de redes neuronais
complexas mantendo um bom desempenho computacional \cite{morrison05}.
%Entretanto, junto com as considerações sobre a abordagem das G
% TODO junta essa de cima com mais de cima pra fazer que vale a pena
% investir em outras coisas antes de partir pra essa solução, pois
% é meio que um tiro de canhão e tem outras coisas a serem melhoradas
% antes disso
% TODO Fala que o resultado sugere que thread ajudaria, mas isso não
% possivel por causa do GIL (explica ele). Multiprocessing seria uma boa,
% mas tem problema também. Aí por fim vem o Cython.


%\begin{table}[ht!]
%\caption{Tempo de execução das simulações relacionadas 
%         à matriz de condutância para diferentes tempos simulados.}
%\label{tab:matrixGt}
%\centering
%    \begin{tabular}{cccc}\hline 
%        & 200 ms & 500 ms & 1000 ms \\ \hline 
%        $G_c$ & 21.52 s & 53.03129 s &  s \\ 
%        $G_g$ & 16.55 s & 41.15 s &  s \\ 
%	\hline
%    \end{tabular}
%\end{table}

\section{Disparos dos Elementos Neuronais}
Na Figura \ref{fig:spkTimes}, cada MN é representado por índices, que 
são distribuídos em ordem crescente no eixo vertical da figura e atribuídos de
forma que seus valores sejam diretamente proporcionais ao tamanho dos
neurônios aos quais estão associados. O eixo horizontal representa os instantes
de disparo, que podem ser observados para cada índice. 

Como visto na Figura \ref{fig:spkTimes}\subref{fig:spkOldxNew}, o uso das
parametrizações nova e antiga resulta em padrões de disparos claramente
distintos. Na nova, os MNs disparam de forma ordenada, do menor para o maior 
(com algumas pequenas variações).
Por outro lado, na antiga, a alta inibição das CRs nos MNs faz com que
alguns destes, em certos instantes, atrasem seus disparos. Como resultado, o
gráfico dos instantes de disparos, nesse caso, possui um aspecto ``fragmentado''.

Essa característica dos instantes de disparos usando a parametrização antiga
pode ser melhor observado na Figura 
\ref{fig:spkTimes}\subref{fig:spkOldZoom}. É possível perceber que existem MNs
maiores disparando antes de outros menores, indicando,
assim, que ocorreu uma certa inversão na ordem de recrutamento.

\begin{figure}[ht]
    \centering
    \subfloat[][]{
        \label{fig:spkOldxNew}
        \includegraphics[scale=0.25]{spkOldxNew.png}
    }
    ~ 
    \subfloat[][]{
        \label{fig:spkOldZoom}
        \includegraphics[scale=0.275]{spkOldZoom.png}
    }
    \caption[Momentos de disparo dos somas de todos os motoneurônios simulados.]{
             Momentos de disparo dos somas de todos os motoneurônios simulados.
             O eixo das ordenadas representa os MNs e o eixo das abcissas, os
             instantes de disparo. \subref{fig:spkOldxNew} Disparos da
             parametrização nova sobreposta à antiga. \subref{fig:spkOldZoom} 
             Zoom em uma parte do gráfico com parametrização antiga.
         }
    \label{fig:spkTimes}
\end{figure}
